# NFS server on clusterd lvm + shared storage

#################################
# Scenario Requirements Section #
#################################
= REQUIREMENTS =
nodes=2
shared_storage=1
floating_ips=1
packages=pacemaker corosync pcs dlm lvm2 lvm2-cluster nfs-utils resource-agents
cluster_init=1
clean_shared_storage=1

######################
# Deployment Scripts #
######################
= SCRIPTS =

##
# Initialize lvm
##
target=all
....
lvmconf --enable-cluster
systemctl disable nfs-server
systemctl stop nfs-server
systemctl disable nfs-lock
systemctl stop nfs-lock
....

##
# setup clvmd and dlm for clustered lvm management
##
target=$PHD_ENV_nodes1
....
tmpfile=mktemp
pcs resource defaults resource-stickiness=100
pcs cluster cib $tmpfile
pcs -f $tmpfile resource create dlm controld op monitor interval=30s on-fail=fence clone interleave=true ordered=true
pcs -f $tmpfile resource create clvmd lsb:clvmd op monitor interval=30s on-fail=fence clone interleave=true ordered=true
pcs -f $tmpfile constraint order start dlm-clone then clvmd-clone
pcs -f $tmpfile constraint colocation add clvmd-clone with dlm-clone
pcs cluster cib-push $tmpfile

phd_wait_pidof "clvmd" 45
....

##
# Make the cluster storage volume group
##
target=$PHD_ENV_nodes1
....
dev=$PHD_ENV_shared_storage1

pvcreate $dev
vgcreate -cy cluster_vg $dev
lvcreate -L128M -n cluster_lv cluster_vg
mkfs.ext4 /dev/cluster_vg/cluster_lv
if [ $? -ne 0 ]; then
	echo "Failed to setup volume group"
	exit 1
fi
vgchange -an cluster_vg
....

##
# Make the lvm resources and floating ip
##
target=$PHD_ENV_nodes1
....
pcs cluster cib lvm-ext4.cib
pcs -f lvm-ext4.cib resource create cluster_vg LVM volgrpname=cluster_vg exclusive=true
pcs -f lvm-ext4.cib resource create nfsshare Filesystem device=/dev/cluster_vg/cluster_lv directory=/nfsshare fstype=ext4
pcs -f lvm-ext4.cib resource create nfs_ip IPaddr2 ip=$PHD_ENV_floating_ips1 cidr_netmask=24
pcs -f lvm-ext4.cib resource group add nfs-group cluster_vg nfsshare nfs_ip
pcs -f lvm-ext4.cib constraint order start clvmd-clone then nfs-group
pcs -f lvm-ext4.cib constraint colocation add nfs-group with clvmd-clone
# put the nfs group on a node we can predict,
# this just helps automate NFS share setup, but will be removed later.
pcs -f lvm-ext4.cib constraint location nfs-group prefers $PHD_ENV_nodes1
pcs cluster cib-push lvm-ext4.cib
....


##
# NFS share setup
##
target=$PHD_ENV_nodes1
....
suffix=$(echo "$PHD_ENV_floating_ips1" | awk -F. '{print $1 "." $2 "." $3 ".0"}')

# Wait for all resources to start
phd_rsc_verify_start_all 60

# Now that our mounts are up, setup the client folders
mkdir /nfsshare/clientdata
touch /nfsshare/clientdata/clientsharefile

# Remove that temporary location constraint now that the folders
# are initialized on the shared storage mount
pcs constraint location remove location-nfs-group-${PHD_ENV_nodes1}-INFINITY

pcs cluster cib nfs-rsc.cib
pcs -f nfs-rsc.cib resource create nfs-daemon nfsserver nfs_shared_infodir=/nfsshare/nfsinfo nfs_ip=$PHD_ENV_floating_ips1
pcs -f nfs-rsc.cib resource create nfs-export exportfs clientspec=${suffix}/255.255.255.0  options=rw,sync directory=/nfsshare/clientdata fsid=0
pcs -f nfs-rsc.cib resource group add nfs-group nfs-daemon nfs-export

pcs cluster cib-push nfs-rsc.cib
....

######################
#    Test Scripts    #
######################
= TESTS =

target=$PHD_ENV_nodes1
....
# Verify all resources have started.
phd_rsc_verify_start_all 60
phd_test_assert $? 0 "Failed to start all resources"

# Verify all resources can stop and start
phd_rsc_stop_all
phd_test_assert $? 0 "Failed to disable resources"
phd_rsc_verify_stop_all 60
phd_test_assert $? 0 "Failed to verify all resources stopped"
phd_rsc_start_all
phd_test_assert $? 0 "Failed to enable all resources"
phd_rsc_verify_start_all 60
phd_test_assert $? 0 "Failed to restart all resources"

# Verify nfs-group can relocate
phd_rsc_relocate nfs-group 60
phd_test_assert $? 0 "Failed to relocate nfs-group"

# Verify nfs-daemon can recover after failure
phd_rsc_verify_start_all 60
phd_test_assert $? 0 "Failed to verify all resources are started before performing recovery test."
phd_rsc_failure_recovery nfs-daemon 60
phd_test_assert $? 0 "Failed to recover nfs-daemon after failure"
....
